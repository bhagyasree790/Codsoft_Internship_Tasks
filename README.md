# 🚢 Titanic Survival Prediction - Task 1

## 🧐 Objective
To explore and understand the Titanic dataset, perform necessary data cleaning and preprocessing, and build a **classification model** using the **K-Nearest Neighbors (KNN)** algorithm to predict whether a passenger survived or not.

## 📊 Dataset
- **Source**: Titanic Dataset (commonly from [Kaggle Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic))
- Contains information like passenger demographics, ticket class, fare, etc.

## 🛠 Tools Used
- **Platform**: Google Colab  
- **Environment**: Anaconda  
- **Language**: Python  

## 📚 Libraries Used
- `pandas` – Data manipulation & analysis  
- `numpy` – Numerical operations  
- `matplotlib` – Data visualization  
- `seaborn` – Statistical data visualization  

## 💡 Machine Learning Algorithm
- **K-Nearest Neighbors (KNN)**  
  Used to classify passengers based on similarity in feature space.

---
---


# 🤖 Task-2: Credit Card Fraud Detection

## 🧐 Objective
The goal of this project is to develop a robust machine learning model capable of identifying **fraudulent credit card transactions**. The major steps involve:

- 🔄 **Data Preprocessing and Normalization**  
- ⚖️ **Handling Class Imbalance**  
- ✂️ **Dataset Splitting**  
- 🧠 **Model Selection and Training**  
- 📊 **Performance Evaluation**

The aim is to accurately classify transactions as either **fraudulent** or **genuine**, even with highly imbalanced data.

---

## 📊 Dataset
- **Name**: Credit Card Fraud Detection Dataset  
- **Source**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)  
- **Details**: Contains transactions made by European cardholders in September 2013, with 492 frauds out of 284,807 transactions.

---

## 🛠 Tools Used
- **Platform**: Google Colab  
- **Environment**: Anaconda  
- **Language**: Python  

---

## 📚 Libraries Used
- `pandas` – Data manipulation  
- `numpy` – Numerical computing  
- `matplotlib` & `seaborn` – Data visualization  
- `sklearn` – Machine learning models and evaluation metrics  

---

## 💡 Machine Learning Algorithms
- **Logistic Regression**
- **K-Nearest Neighbors (KNN)**
- **Isolation Forest**
- **Local Outlier Factor (LOF)**

Each model is trained and evaluated to compare performance, especially under imbalanced conditions.

---    
---


# 📑 Task-3: Sales Prediction

## 🤓 Objective
This project aims to build a **concise and effective sales prediction model** using machine learning techniques in Python. It involves:

- 📈 Collecting and exploring sales-related data  
- 🧹 Performing data preprocessing to ensure quality  
- 🧠 Training models to predict future sales based on advertising expenditure and audience segmentation  
- 🧩 Integrating the trained model for **business decision-making**, **ad strategy optimization**, and **efficient resource allocation**

---

## 📊 Dataset
- **Name**: Sales Prediction Dataset  
- **Type**: Tabular dataset containing advertising budgets and corresponding sales  
- **Focus**: Simple Linear Regression scenario (e.g., TV Ad Spend vs Sales)  
- **Source**: Custom/pre-loaded in ML tutorials (e.g., from CSV)

---

## 🛠 Tools Used
- **Platform**: Google Colab  
- **Environment**: Anaconda  
- **Language**: Python  

---

## 📚 Libraries Used
- `pandas` – Data loading and preprocessing  
- `numpy` – Numerical operations  
- `matplotlib` & `seaborn` – Data visualization  
- `sklearn` – Model building and evaluation  

---

## 💡 Machine Learning Algorithms
- **Linear Regression**  
- **Decision Trees**  
- **K-Nearest Neighbors (KNN)**  
- **Support Vector Machines (SVM)**  

All models are trained, tested, and compared to find the most suitable one for real-world sales forecasting.

---

## 🚀 Workflow
1. **Exploratory Data Analysis (EDA)** – Understand distribution and correlations.
2. **Preprocessing** – Normalize/scale features and handle missing data.
3. **Handling Imbalance** – Techniques like undersampling, oversampling, SMOTE.
4. **Model Training** – Train models like Logistic Regression, KNN, Isolation Forest, LOF.
5. **Evaluation** – Accuracy, Precision, Recall, F1-Score, AUC-ROC.

---

## 📈 Results
Achieved a recall of **XX%** and precision of **YY%** on detecting fraudulent transactions using the best-performing model. *(Update after testing)*

---

## 🙌 Acknowledgements
Dataset provided by Codsoft

---


