🚢 Task-1: Titanic Survival Prediction
      🧐Objective: Understand the Dataset & cleanup (if required) and then build a classification model to predict whether the passenger survives or not.
      📊Dataset: Titanic Dataset
      🛠 Tools: Google Colab, Python, Anaconda
      📚 Libraries: Pandas, Numpy, Matplotlib, Seaborn
      💡 ML Algorithm: K-Nearest Neighbors



🤖Task-2: CREDIT CARD FRAUD DETECTION
  🧐Objective: The objective of this project is to develop an effective machine learning model for the identification of fraudulent credit card transactions. The key tasks include preprocessing and normalizing the transaction data, addressing class imbalance issues, and implementing a classification algorithm, such as logistic regression or random forests, to accurately classify transactions as either fraudulent or genuine. The project aims to achieve the following specific goals:
      - Data Preprocessing and Normalization
      - Handling Class Imbalance
      - Dataset Splitting
      - Model Selection and Training
      - Performance Evaluation
  📊Dataset: Credit Card Fraud Detection Dataset
  🛠 Tools: Google Colab, Python, Anaconda
  📚 Libraries: Pandas, Numpy, Matplotlib, Seaborn, Sklearn
  💡 ML Algorithm: LogisticRegression, IsolationForest, LocalOutlierFactor, K-Nearest Neighbors        



📑Task-3: Sales Prediction
  🤓Objective: The objective of this project is to develop a concise and effective sales prediction model using machine learning in Python. This involves collecting and exploring relevant data on sales, advertising expenditure, and audience segmentation, followed by preprocessing steps to ensure data quality. The ultimate goal is to integrate the trained model into business systems, providing a practical tool for forecasting sales, optimizing advertising strategies, and enabling efficient resource allocation.
  📊Dataset: Sales Prediction (Simple Linear Regression)
  🛠 Tools: Google Colab, Python, Anaconda
  📚 Libraries: Pandas, Numpy, Matplotlib, Seaborn, Sklearn
  💡 ML Algorithm: Linear Regression, Decision Trees, K-nearest Neighbors, Support Vector Machines
